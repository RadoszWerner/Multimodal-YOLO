{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DetectionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-3): 4 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-3): 4 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(576, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(960, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(960, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Detect(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Wczytaj model YOLOv8m (automatycznie pobierze pretrenowane wagi)\n",
    "model = YOLO('yolov8m.pt')\n",
    "\n",
    "# Wyświetl podstawową strukturę modelu\n",
    "print(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.100 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.94  Python-3.12.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=datasets/llvip_fused_yuv/data.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=my_yolov8_exp_2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\my_yolov8_exp_2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Projects\\multimodal\\datasets\\llvip_fused_yuv\\labels\\train.cache... 9620 images, 2 backgrounds, 0 corrupt: 100%|██████████| 9620/9620 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Projects\\multimodal\\datasets\\llvip_fused_yuv\\labels\\val.cache... 2405 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2405/2405 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\my_yolov8_exp_2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\my_yolov8_exp_2\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40      6.24G      1.444     0.8771      1.302         14        640: 100%|██████████| 602/602 [03:58<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:25<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.883      0.828      0.906      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40      7.21G      1.464     0.8582      1.333         24        640: 100%|██████████| 602/602 [03:36<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.914      0.839      0.921      0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40      6.55G      1.428     0.8119      1.318         12        640: 100%|██████████| 602/602 [03:29<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:25<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.931      0.862      0.931      0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40      6.54G      1.392     0.7641      1.302         23        640: 100%|██████████| 602/602 [03:30<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:24<00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.908      0.907      0.951      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40      6.56G       1.36     0.7185      1.287         14        640: 100%|██████████| 602/602 [03:29<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.931      0.905      0.956      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40      6.55G      1.333     0.6849      1.269         28        640: 100%|██████████| 602/602 [03:24<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.926      0.902      0.957      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40      6.59G      1.322     0.6693      1.273         17        640: 100%|██████████| 602/602 [03:24<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777       0.92       0.88       0.94      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40      6.57G      1.302     0.6485      1.264         13        640: 100%|██████████| 602/602 [03:23<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:21<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.932      0.921      0.966      0.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40      6.54G      1.285     0.6359      1.253         21        640: 100%|██████████| 602/602 [03:24<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.938       0.92      0.967      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40      6.53G      1.278     0.6238      1.251         20        640: 100%|██████████| 602/602 [03:24<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:50<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.942      0.912      0.965      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40      6.59G      1.256     0.6046      1.237         22        640: 100%|██████████| 602/602 [03:24<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.938      0.927      0.969      0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40      6.56G       1.25     0.5987      1.239         18        640: 100%|██████████| 602/602 [03:27<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [01:14<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.945      0.925      0.966      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40      6.57G       1.24     0.5884      1.231         13        640: 100%|██████████| 602/602 [03:26<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:24<00:00,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.941      0.936      0.972      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40      6.58G      1.229     0.5802      1.225         14        640: 100%|██████████| 602/602 [03:28<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:53<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.942      0.936      0.971      0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40      6.54G      1.223     0.5733      1.217         15        640: 100%|██████████| 602/602 [03:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.945      0.931      0.972      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40      6.53G      1.212     0.5648      1.218          9        640: 100%|██████████| 602/602 [03:28<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.944      0.935      0.972      0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40      6.58G      1.215     0.5628      1.214         22        640: 100%|██████████| 602/602 [03:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777       0.94      0.939      0.974      0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40      6.56G      1.203     0.5506      1.217         23        640: 100%|██████████| 602/602 [03:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:50<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.941      0.942      0.974      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40      6.55G      1.193     0.5423      1.206         22        640: 100%|██████████| 602/602 [03:26<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:24<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.942      0.943      0.975      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40      6.55G      1.189     0.5407      1.211          8        640: 100%|██████████| 602/602 [03:25<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.949      0.937      0.975      0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40      6.55G      1.173     0.5327      1.198         11        640: 100%|██████████| 602/602 [03:26<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.946      0.939      0.975       0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40      6.55G      1.165      0.524      1.195         14        640: 100%|██████████| 602/602 [03:26<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.944      0.944      0.977      0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40      6.58G       1.16     0.5174       1.19          9        640: 100%|██████████| 602/602 [03:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.946      0.944      0.977      0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40      6.54G      1.152     0.5124      1.185         11        640: 100%|██████████| 602/602 [03:26<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.951      0.941      0.979      0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40      6.55G      1.149     0.5145      1.179          9        640: 100%|██████████| 602/602 [03:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.951      0.945      0.978      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40      6.57G      1.138     0.4979      1.182         21        640: 100%|██████████| 602/602 [03:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.949      0.943      0.979      0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40       6.6G      1.131     0.4965      1.175         18        640: 100%|██████████| 602/602 [03:29<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:32<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.951      0.945       0.98      0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40      6.55G      1.121     0.4907      1.166         22        640: 100%|██████████| 602/602 [03:25<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:50<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777       0.95      0.945      0.979      0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40      6.53G      1.115     0.4859      1.169         11        640: 100%|██████████| 602/602 [03:27<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.945      0.949      0.979      0.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/40      6.57G      1.106     0.4794      1.158         26        640: 100%|██████████| 602/602 [03:24<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.952      0.948       0.98      0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/40      6.55G      1.081     0.4488      1.157         13        640: 100%|██████████| 602/602 [03:23<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.948      0.947       0.98      0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/40      6.53G      1.073     0.4424      1.155         13        640: 100%|██████████| 602/602 [03:24<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.952      0.942      0.979      0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/40      6.55G      1.057     0.4349      1.143          8        640: 100%|██████████| 602/602 [03:23<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.951      0.943       0.98      0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/40      6.53G      1.049     0.4307       1.14         11        640: 100%|██████████| 602/602 [03:23<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:23<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.945      0.949      0.981      0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/40      6.54G      1.036     0.4214      1.132          7        640: 100%|██████████| 602/602 [03:23<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:28<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.949      0.947      0.981      0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/40      6.53G      1.028     0.4163       1.13         11        640: 100%|██████████| 602/602 [03:23<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777       0.95      0.947      0.982      0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/40      6.55G      1.019     0.4109      1.121          8        640: 100%|██████████| 602/602 [03:23<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.951      0.947      0.981      0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/40      6.52G      1.011     0.4037      1.109         10        640: 100%|██████████| 602/602 [03:23<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:24<00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.953      0.949      0.982      0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/40      6.56G      1.001     0.4001      1.101         15        640: 100%|██████████| 602/602 [03:22<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:21<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.952      0.952      0.981      0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/40      6.53G     0.9946     0.3946      1.105         15        640: 100%|██████████| 602/602 [03:23<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.954      0.949      0.982      0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40 epochs completed in 2.625 hours.\n",
      "Optimizer stripped from runs\\detect\\my_yolov8_exp_2\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from runs\\detect\\my_yolov8_exp_2\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating runs\\detect\\my_yolov8_exp_2\\weights\\best.pt...\n",
      "Ultralytics 8.3.94  Python-3.12.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 76/76 [00:22<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2405       6777      0.954      0.949      0.982      0.696\n",
      "Speed: 0.1ms preprocess, 4.8ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\my_yolov8_exp_2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model2 = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "results2 = model2.train(\n",
    "    data=\"datasets/llvip_fused_yuv/data.yaml\",\n",
    "    epochs=40,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,  # GPU\n",
    "    name=\"my_yolov8_exp_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000023FA6B64C80>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,\n",
       "            0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,\n",
       "            0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,\n",
       "            0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99972,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,\n",
       "            0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,\n",
       "            0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,\n",
       "            0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,\n",
       "            0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99953,     0.99931,     0.99931,     0.99931,     0.99931,     0.99931,     0.99931,     0.99931,     0.99908,     0.99908,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,\n",
       "            0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,\n",
       "            0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99892,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,\n",
       "            0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99876,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,\n",
       "            0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99861,     0.99841,     0.99841,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,     0.99826,\n",
       "            0.99826,     0.99809,     0.99809,     0.99809,     0.99809,     0.99809,     0.99809,     0.99809,     0.99809,     0.99809,     0.99791,     0.99791,     0.99773,     0.99773,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,\n",
       "            0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,\n",
       "            0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,     0.99771,      0.9976,      0.9976,      0.9976,      0.9976,      0.9976,      0.9976,      0.9976,\n",
       "             0.9976,      0.9976,      0.9976,      0.9976,      0.9976,      0.9976,      0.9976,      0.9976,      0.9976,      0.9976,     0.99743,     0.99726,     0.99726,     0.99694,     0.99694,     0.99694,     0.99668,     0.99668,     0.99668,     0.99668,     0.99668,     0.99668,     0.99668,\n",
       "            0.99668,     0.99668,     0.99668,     0.99668,     0.99668,     0.99668,     0.99668,     0.99668,     0.99668,     0.99652,     0.99652,     0.99652,     0.99642,     0.99642,     0.99642,     0.99642,     0.99642,     0.99642,     0.99642,     0.99642,     0.99642,     0.99642,     0.99642,\n",
       "            0.99625,     0.99612,     0.99612,     0.99612,     0.99612,     0.99612,       0.996,       0.996,       0.996,       0.996,       0.996,       0.996,       0.996,     0.99585,     0.99585,      0.9957,     0.99555,     0.99555,     0.99555,     0.99525,     0.99525,     0.99516,     0.99516,\n",
       "            0.99516,     0.99516,     0.99516,     0.99516,     0.99516,     0.99516,     0.99516,     0.99516,     0.99501,     0.99486,     0.99475,     0.99475,     0.99475,     0.99475,     0.99475,     0.99475,     0.99475,     0.99449,     0.99449,     0.99449,     0.99449,     0.99449,     0.99449,\n",
       "            0.99449,     0.99436,     0.99436,     0.99422,     0.99422,     0.99408,     0.99396,     0.99396,     0.99396,     0.99396,     0.99396,     0.99382,     0.99369,     0.99369,     0.99369,     0.99355,     0.99327,     0.99298,     0.99284,     0.99271,     0.99271,     0.99257,     0.99245,\n",
       "            0.99245,     0.99245,     0.99231,     0.99217,     0.99204,      0.9919,     0.99177,     0.99162,      0.9915,     0.99136,     0.99122,     0.99095,     0.99052,     0.99026,     0.99026,        0.99,        0.99,     0.98986,     0.98974,      0.9896,     0.98947,     0.98921,     0.98921,\n",
       "            0.98897,     0.98897,     0.98897,     0.98884,     0.98871,     0.98859,     0.98859,     0.98821,     0.98821,     0.98809,     0.98809,     0.98782,     0.98727,     0.98673,     0.98662,     0.98635,     0.98609,     0.98597,     0.98585,     0.98572,      0.9856,     0.98548,     0.98523,\n",
       "            0.98511,     0.98432,     0.98432,      0.9842,     0.98367,     0.98355,     0.98275,     0.98264,     0.98254,     0.98254,     0.98176,     0.98165,     0.98127,     0.98075,      0.9805,     0.97932,     0.97881,     0.97843,     0.97766,     0.97705,     0.97667,     0.97616,     0.97527,\n",
       "            0.97438,     0.97389,     0.97315,     0.97305,     0.97267,     0.97219,      0.9716,     0.97109,     0.97061,     0.97026,     0.96964,     0.96879,     0.96843,     0.96771,     0.96623,      0.9655,     0.96429,     0.96332,     0.96249,      0.9609,     0.95933,     0.95912,     0.95844,\n",
       "            0.95675,      0.9557,     0.95464,     0.95399,     0.95364,     0.95175,     0.95072,      0.9491,     0.94783,      0.9442,     0.94249,     0.93832,     0.93584,     0.93417,     0.93124,     0.92778,     0.92604,     0.92421,     0.92147,     0.91823,     0.91467,     0.91234,     0.90756,\n",
       "            0.90293,     0.90059,     0.89668,     0.89239,     0.88653,     0.88327,     0.87724,     0.87092,     0.86642,     0.86239,     0.86021,     0.85426,     0.84986,     0.84671,     0.83932,     0.83586,     0.83038,       0.827,     0.81608,     0.80829,     0.80263,     0.79216,     0.78589,\n",
       "            0.77779,     0.76739,     0.75767,     0.74919,     0.73305,     0.72691,     0.71752,     0.70516,     0.69786,      0.6889,     0.67831,     0.67081,     0.66357,     0.65466,     0.63655,      0.6312,     0.61913,     0.61379,     0.60471,     0.58757,     0.56896,     0.55221,     0.54018,\n",
       "            0.53516,     0.52321,     0.51011,     0.49953,     0.48654,     0.46965,     0.45887,     0.44803,     0.43564,     0.41708,     0.39151,     0.37598,     0.36679,     0.34287,     0.33279,     0.31665,     0.30808,     0.28613,     0.26567,     0.24761,     0.23723,     0.21898,     0.20073,\n",
       "            0.18248,     0.16424,     0.14599,     0.12774,     0.10949,    0.091242,    0.072994,    0.054745,    0.036497,    0.018248,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.38526,     0.38545,     0.48789,     0.54806,     0.58992,      0.6207,     0.64494,     0.66508,     0.68159,     0.69473,      0.7075,     0.71859,     0.72875,     0.73864,     0.74663,     0.75319,     0.76016,     0.76476,     0.77064,     0.77625,     0.78065,     0.78586,     0.78978,\n",
       "            0.79328,     0.79695,     0.80066,     0.80431,      0.8079,      0.8112,     0.81455,      0.8179,     0.82047,     0.82334,     0.82587,     0.82779,     0.82984,     0.83215,      0.8347,     0.83683,     0.83828,      0.8402,     0.84182,     0.84333,     0.84551,     0.84661,     0.84813,\n",
       "            0.84988,     0.85124,     0.85277,     0.85401,      0.8554,     0.85671,     0.85834,     0.85935,     0.86053,     0.86193,      0.8635,     0.86518,     0.86669,     0.86781,     0.86894,     0.86982,     0.87055,     0.87149,     0.87229,     0.87311,     0.87393,     0.87514,     0.87612,\n",
       "             0.8773,     0.87826,     0.87898,      0.8799,     0.88043,     0.88109,     0.88182,      0.8826,     0.88313,     0.88358,     0.88414,     0.88462,     0.88547,      0.8861,     0.88686,      0.8876,     0.88846,     0.88884,     0.88927,     0.88939,     0.88971,        0.89,     0.89065,\n",
       "             0.8912,     0.89169,     0.89208,     0.89273,     0.89326,     0.89416,     0.89446,     0.89477,     0.89496,     0.89546,     0.89602,     0.89638,     0.89654,     0.89744,     0.89803,     0.89841,     0.89852,     0.89888,     0.89918,     0.89954,     0.89975,     0.90043,      0.9007,\n",
       "             0.9013,     0.90169,     0.90243,     0.90274,     0.90295,     0.90357,     0.90368,     0.90418,     0.90465,      0.9048,     0.90509,     0.90539,     0.90588,     0.90591,     0.90655,     0.90723,     0.90765,     0.90781,     0.90812,     0.90837,     0.90883,     0.90916,      0.9093,\n",
       "            0.90957,      0.9098,     0.91022,     0.91079,     0.91111,     0.91103,     0.91133,     0.91147,     0.91171,     0.91185,     0.91181,     0.91204,     0.91238,     0.91267,     0.91288,     0.91325,     0.91362,     0.91387,     0.91407,     0.91443,     0.91468,      0.9151,     0.91548,\n",
       "            0.91555,     0.91554,     0.91596,     0.91618,     0.91626,     0.91628,      0.9165,     0.91688,     0.91693,     0.91703,     0.91736,      0.9175,     0.91768,     0.91785,     0.91817,     0.91829,     0.91856,     0.91843,     0.91865,     0.91875,     0.91891,     0.91895,     0.91931,\n",
       "            0.91937,     0.91959,      0.9196,     0.91978,     0.91984,     0.91992,     0.92011,     0.92026,      0.9201,     0.92019,     0.92048,     0.92066,     0.92082,     0.92116,     0.92123,     0.92136,     0.92157,     0.92144,     0.92154,     0.92175,      0.9219,     0.92223,     0.92244,\n",
       "            0.92237,     0.92253,     0.92261,     0.92264,     0.92275,     0.92279,     0.92291,     0.92292,     0.92287,     0.92299,       0.923,     0.92326,     0.92336,     0.92359,     0.92374,     0.92377,      0.9238,     0.92391,     0.92402,     0.92404,     0.92417,     0.92428,     0.92442,\n",
       "            0.92454,     0.92462,     0.92488,     0.92495,     0.92501,     0.92497,     0.92508,     0.92509,     0.92517,     0.92519,     0.92556,     0.92556,     0.92567,     0.92582,     0.92622,     0.92617,     0.92626,      0.9264,     0.92635,     0.92651,     0.92663,     0.92663,     0.92653,\n",
       "            0.92639,     0.92644,     0.92665,      0.9267,     0.92674,     0.92665,     0.92671,     0.92666,     0.92662,     0.92673,     0.92682,     0.92671,     0.92672,     0.92672,     0.92688,     0.92698,     0.92692,     0.92706,     0.92706,     0.92674,     0.92669,     0.92652,     0.92641,\n",
       "            0.92644,     0.92648,     0.92637,     0.92642,     0.92646,     0.92648,     0.92638,      0.9264,     0.92661,     0.92644,     0.92647,     0.92652,     0.92658,     0.92664,     0.92657,     0.92659,     0.92649,     0.92638,     0.92637,     0.92642,      0.9261,     0.92598,     0.92617,\n",
       "              0.926,     0.92616,     0.92605,     0.92612,      0.9262,     0.92608,     0.92607,     0.92628,      0.9265,     0.92626,     0.92632,      0.9263,      0.9263,     0.92632,     0.92619,     0.92613,     0.92631,      0.9262,     0.92624,     0.92621,     0.92613,     0.92605,     0.92615,\n",
       "            0.92625,     0.92623,     0.92624,     0.92598,     0.92594,     0.92588,      0.9258,     0.92587,     0.92596,     0.92603,      0.9261,     0.92607,     0.92598,     0.92585,     0.92579,     0.92581,     0.92585,     0.92588,      0.9259,     0.92591,     0.92567,     0.92547,     0.92536,\n",
       "            0.92523,     0.92526,     0.92534,     0.92514,     0.92513,     0.92525,     0.92511,     0.92507,      0.9251,     0.92489,     0.92479,     0.92459,     0.92458,     0.92441,      0.9244,     0.92425,     0.92427,     0.92402,      0.9239,     0.92378,     0.92378,     0.92379,     0.92369,\n",
       "            0.92357,     0.92328,     0.92338,     0.92342,     0.92334,     0.92334,      0.9232,      0.9229,     0.92253,     0.92249,     0.92238,     0.92235,     0.92212,     0.92208,     0.92194,     0.92206,     0.92198,     0.92196,      0.9219,      0.9219,     0.92181,     0.92176,     0.92157,\n",
       "            0.92163,     0.92179,     0.92168,      0.9214,     0.92147,     0.92137,     0.92124,     0.92129,     0.92092,     0.92086,     0.92079,     0.92082,     0.92074,     0.92059,     0.92063,     0.92051,     0.92049,     0.92043,     0.92032,      0.9203,     0.92003,        0.92,        0.92,\n",
       "            0.91975,     0.91973,     0.91963,     0.91963,     0.91973,     0.91958,     0.91965,     0.91965,     0.91966,     0.91956,     0.91944,     0.91921,     0.91917,     0.91913,     0.91877,     0.91873,     0.91878,     0.91863,     0.91848,     0.91831,     0.91825,     0.91795,     0.91786,\n",
       "            0.91787,     0.91773,     0.91751,     0.91735,     0.91714,       0.917,     0.91676,     0.91676,     0.91646,     0.91634,     0.91609,     0.91597,     0.91595,     0.91596,      0.9159,     0.91584,     0.91551,     0.91541,     0.91538,     0.91513,     0.91503,     0.91501,     0.91511,\n",
       "            0.91487,     0.91472,     0.91471,      0.9146,     0.91425,     0.91409,     0.91387,     0.91386,     0.91393,     0.91365,     0.91353,     0.91346,     0.91332,     0.91308,     0.91288,     0.91277,     0.91275,     0.91268,     0.91232,     0.91217,     0.91213,     0.91175,     0.91153,\n",
       "            0.91134,     0.91118,     0.91077,     0.91061,      0.9102,     0.90996,     0.90977,      0.9096,     0.90944,     0.90923,     0.90869,     0.90851,      0.9085,     0.90838,     0.90818,     0.90818,     0.90797,     0.90798,     0.90769,     0.90756,     0.90756,     0.90744,     0.90734,\n",
       "            0.90702,     0.90677,     0.90642,     0.90628,     0.90624,     0.90608,     0.90587,      0.9057,     0.90564,     0.90558,     0.90521,      0.9052,     0.90497,     0.90476,     0.90444,      0.9039,     0.90354,      0.9032,     0.90281,     0.90259,     0.90237,     0.90199,     0.90178,\n",
       "            0.90139,     0.90141,     0.90124,     0.90097,     0.90079,     0.90041,     0.90023,     0.90003,     0.89997,     0.89961,     0.89959,     0.89936,     0.89904,     0.89868,     0.89843,     0.89795,     0.89783,     0.89771,     0.89751,     0.89741,     0.89709,     0.89677,     0.89647,\n",
       "            0.89628,      0.8961,     0.89596,     0.89582,     0.89581,      0.8958,     0.89563,     0.89542,     0.89529,     0.89516,     0.89499,     0.89461,     0.89442,      0.8944,      0.8941,     0.89361,     0.89332,     0.89301,     0.89267,     0.89246,     0.89184,     0.89147,     0.89129,\n",
       "              0.891,     0.89085,     0.89024,     0.88963,      0.8893,     0.88903,     0.88875,     0.88865,     0.88832,     0.88818,     0.88791,     0.88774,      0.8871,      0.8868,     0.88641,     0.88615,     0.88591,     0.88585,     0.88532,     0.88509,     0.88483,     0.88464,     0.88449,\n",
       "             0.8838,     0.88315,      0.8828,     0.88245,     0.88223,     0.88195,     0.88157,     0.88144,       0.881,     0.88021,     0.87982,      0.8795,     0.87929,      0.8791,     0.87884,     0.87839,     0.87821,     0.87806,     0.87769,      0.8774,     0.87701,     0.87675,      0.8764,\n",
       "            0.87598,     0.87538,     0.87485,     0.87447,     0.87412,     0.87386,     0.87348,     0.87312,     0.87249,      0.8721,     0.87181,     0.87129,     0.87075,     0.87055,     0.86984,     0.86912,     0.86878,     0.86837,      0.8681,     0.86751,       0.867,     0.86678,     0.86619,\n",
       "            0.86525,       0.865,     0.86459,     0.86424,     0.86367,     0.86326,     0.86291,     0.86263,     0.86175,     0.86106,     0.86078,     0.85976,     0.85912,     0.85854,     0.85784,     0.85689,     0.85615,     0.85563,     0.85541,     0.85487,     0.85428,     0.85373,     0.85278,\n",
       "            0.85212,     0.85116,     0.85068,     0.85029,     0.84968,     0.84892,     0.84831,      0.8478,     0.84742,     0.84717,     0.84612,     0.84575,     0.84484,     0.84432,     0.84347,     0.84306,     0.84203,     0.84145,     0.84072,     0.83997,     0.83948,      0.8389,     0.83844,\n",
       "              0.838,      0.8373,     0.83613,     0.83544,     0.83419,     0.83297,     0.83249,     0.83162,     0.83115,     0.82971,     0.82877,     0.82805,     0.82729,     0.82654,     0.82592,     0.82498,      0.8242,     0.82324,      0.8217,     0.82025,     0.81954,     0.81793,     0.81671,\n",
       "            0.81548,     0.81426,     0.81314,     0.81225,     0.81095,      0.8098,     0.80853,     0.80782,       0.806,       0.805,     0.80346,     0.80241,     0.80158,     0.80067,     0.79982,     0.79911,     0.79773,     0.79638,     0.79456,     0.79246,     0.79146,     0.78967,     0.78791,\n",
       "            0.78642,     0.78452,     0.78278,      0.7815,     0.78032,      0.7782,     0.77712,     0.77561,     0.77353,     0.77219,     0.77035,     0.76865,     0.76686,     0.76514,     0.76393,     0.76198,     0.76096,     0.75914,     0.75696,      0.7552,     0.75336,     0.75176,     0.74997,\n",
       "            0.74703,     0.74439,     0.74255,     0.74008,     0.73809,     0.73624,     0.73361,     0.73123,     0.72875,      0.7271,     0.72524,     0.72291,     0.72078,     0.71843,     0.71529,     0.71172,     0.70896,     0.70546,     0.70204,     0.69857,     0.69603,     0.69186,     0.68861,\n",
       "            0.68586,     0.68361,     0.68081,     0.67828,     0.67369,     0.67072,      0.6673,     0.66353,     0.66035,     0.65623,     0.65244,     0.64833,     0.64351,     0.63995,     0.63556,     0.63165,      0.6279,      0.6238,     0.61984,     0.61512,     0.61003,     0.60345,     0.59903,\n",
       "            0.59342,      0.5894,     0.58236,     0.57696,     0.57018,      0.5641,      0.5597,     0.55261,     0.54693,     0.54016,      0.5321,     0.52673,     0.52067,     0.51412,      0.5062,      0.4986,     0.49209,     0.48406,     0.47687,     0.46818,     0.46076,     0.45343,     0.44513,\n",
       "            0.43705,      0.4282,     0.42065,     0.41252,     0.40532,     0.39772,     0.38915,     0.38181,     0.37315,     0.36373,     0.35443,     0.34841,     0.33908,     0.32982,     0.32133,     0.31314,     0.30291,     0.29465,     0.28685,      0.2758,     0.26902,     0.26012,     0.25119,\n",
       "            0.24293,     0.23504,     0.22556,     0.21571,     0.20552,     0.19775,     0.18957,     0.18002,     0.17411,     0.16537,     0.15671,     0.14828,      0.1411,     0.13431,     0.12686,     0.11982,     0.11238,     0.10527,    0.096125,    0.088121,    0.082098,    0.076665,    0.070872,\n",
       "             0.0645,    0.060869,    0.055681,    0.050968,    0.047774,    0.044718,    0.041618,    0.039323,     0.03489,    0.031822,    0.028726,     0.02606,    0.023408,    0.022617,    0.019896,    0.017985,    0.016572,    0.014533,    0.013714,    0.012083,     0.01067,   0.0087463,   0.0066663,\n",
       "          0.0053138,   0.0045307,   0.0042361,   0.0038388,   0.0033371,     0.00313,   0.0023099,   0.0021053,   0.0016669,   0.0016135,   0.0015601,   0.0015068,   0.0014534,   0.0013582,   0.0012545,    0.000918,  0.00073857,  0.00030236,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.23935,      0.2395,     0.32462,     0.38076,     0.42282,     0.45565,     0.48267,     0.50621,     0.52602,     0.54251,     0.55874,     0.57295,     0.58615,      0.5992,     0.61037,     0.61974,     0.62938,      0.6364,     0.64481,     0.65287,     0.65946,     0.66747,     0.67362,\n",
       "            0.67897,     0.68461,     0.69037,     0.69613,     0.70198,     0.70758,     0.71283,     0.71811,      0.7223,     0.72711,      0.7315,      0.7348,     0.73819,       0.742,     0.74622,     0.74971,     0.75241,     0.75564,     0.75843,     0.76106,     0.76468,     0.76672,     0.76938,\n",
       "            0.77227,     0.77484,     0.77757,     0.77994,     0.78251,     0.78487,     0.78785,     0.78974,     0.79215,      0.7948,     0.79764,      0.8006,     0.80344,     0.80574,     0.80777,     0.80956,     0.81105,     0.81291,      0.8143,     0.81582,     0.81741,     0.81974,     0.82165,\n",
       "            0.82391,     0.82569,     0.82714,     0.82888,     0.83021,     0.83175,     0.83334,     0.83475,     0.83598,     0.83726,     0.83843,     0.83963,     0.84125,     0.84269,     0.84407,      0.8454,     0.84725,     0.84814,     0.84904,     0.84985,     0.85054,     0.85136,     0.85266,\n",
       "            0.85376,     0.85508,     0.85579,     0.85699,     0.85817,     0.86004,     0.86101,     0.86169,     0.86255,      0.8637,     0.86495,     0.86569,     0.86632,     0.86811,     0.86953,     0.87058,      0.8711,     0.87198,     0.87276,     0.87343,     0.87384,     0.87524,     0.87584,\n",
       "            0.87699,     0.87783,     0.87934,     0.87992,     0.88044,     0.88184,     0.88238,     0.88345,     0.88445,     0.88513,     0.88594,     0.88653,     0.88768,     0.88808,     0.88931,     0.89072,     0.89177,     0.89208,      0.8929,      0.8936,     0.89472,     0.89546,     0.89585,\n",
       "            0.89672,     0.89746,     0.89844,     0.89956,     0.90042,     0.90071,      0.9013,     0.90181,      0.9024,     0.90283,     0.90292,     0.90361,     0.90452,     0.90532,     0.90573,     0.90645,     0.90724,     0.90803,     0.90856,     0.90955,     0.91011,     0.91096,     0.91192,\n",
       "            0.91233,     0.91265,      0.9136,     0.91403,     0.91425,     0.91459,     0.91515,     0.91597,     0.91649,      0.9168,     0.91748,     0.91776,     0.91823,     0.91894,     0.91958,     0.91983,     0.92049,     0.92071,     0.92152,     0.92183,     0.92223,     0.92255,     0.92333,\n",
       "            0.92357,     0.92403,     0.92478,     0.92539,     0.92575,     0.92604,     0.92659,     0.92711,     0.92716,     0.92745,     0.92817,     0.92866,     0.92911,     0.93002,     0.93032,     0.93072,     0.93114,     0.93145,     0.93184,     0.93226,     0.93257,      0.9335,     0.93394,\n",
       "            0.93417,     0.93462,     0.93517,     0.93549,     0.93583,     0.93606,     0.93629,     0.93645,     0.93662,     0.93724,     0.93751,     0.93804,     0.93838,     0.93885,     0.93929,     0.93947,     0.93954,     0.93976,     0.94005,      0.9403,     0.94062,     0.94105,     0.94134,\n",
       "            0.94172,     0.94189,     0.94248,     0.94283,     0.94295,     0.94328,     0.94374,     0.94391,     0.94406,     0.94423,     0.94502,     0.94527,      0.9455,     0.94582,     0.94665,     0.94694,     0.94739,     0.94783,     0.94785,     0.94818,     0.94853,     0.94887,     0.94901,\n",
       "            0.94913,     0.94963,     0.95037,     0.95058,     0.95079,     0.95083,       0.951,     0.95106,     0.95105,     0.95144,     0.95162,     0.95164,     0.95195,     0.95222,     0.95255,     0.95305,     0.95317,     0.95364,     0.95387,     0.95396,     0.95416,     0.95453,     0.95475,\n",
       "            0.95522,     0.95563,     0.95579,     0.95617,     0.95627,     0.95657,     0.95664,     0.95681,     0.95726,     0.95746,     0.95766,      0.9579,     0.95803,     0.95816,     0.95843,     0.95878,     0.95877,     0.95888,     0.95896,     0.95924,     0.95921,     0.95932,     0.95982,\n",
       "             0.9598,     0.96016,     0.96048,     0.96089,     0.96109,     0.96125,     0.96137,     0.96187,     0.96249,      0.9626,     0.96315,     0.96355,     0.96368,      0.9638,      0.9638,     0.96387,     0.96429,     0.96428,     0.96454,     0.96465,     0.96501,      0.9651,     0.96538,\n",
       "            0.96584,     0.96592,     0.96599,      0.9661,     0.96622,     0.96631,     0.96646,     0.96671,     0.96692,     0.96719,     0.96758,      0.9677,     0.96795,     0.96794,      0.9681,      0.9683,     0.96852,     0.96859,     0.96863,     0.96867,     0.96867,     0.96878,      0.9689,\n",
       "            0.96889,      0.9694,     0.96964,     0.96972,     0.96983,     0.97014,     0.97025,     0.97029,     0.97036,     0.97037,     0.97054,      0.9706,     0.97097,     0.97096,     0.97109,     0.97108,     0.97158,     0.97157,     0.97169,     0.97181,     0.97193,     0.97206,     0.97206,\n",
       "             0.9723,     0.97234,     0.97254,      0.9728,      0.9728,     0.97291,     0.97304,      0.9731,     0.97313,     0.97338,     0.97359,     0.97382,     0.97387,       0.974,     0.97408,     0.97438,     0.97463,     0.97489,     0.97489,     0.97514,     0.97527,     0.97552,     0.97551,\n",
       "            0.97577,     0.97616,     0.97616,     0.97619,     0.97664,     0.97666,     0.97665,     0.97704,     0.97703,     0.97703,     0.97702,     0.97715,     0.97741,     0.97754,     0.97766,     0.97797,     0.97805,     0.97843,      0.9786,     0.97869,     0.97871,     0.97881,     0.97894,\n",
       "            0.97893,     0.97906,     0.97919,     0.97934,     0.97958,     0.97985,     0.98001,     0.98023,      0.9805,     0.98062,     0.98062,     0.98074,     0.98087,     0.98113,     0.98125,     0.98132,     0.98152,     0.98156,     0.98164,     0.98163,     0.98163,     0.98175,     0.98182,\n",
       "            0.98232,     0.98254,     0.98253,     0.98253,     0.98252,     0.98252,     0.98251,      0.9826,     0.98263,     0.98263,     0.98262,     0.98288,     0.98295,     0.98328,     0.98331,     0.98355,     0.98354,      0.9836,     0.98367,     0.98366,     0.98365,     0.98379,     0.98417,\n",
       "            0.98419,     0.98418,     0.98432,     0.98431,      0.9843,      0.9843,     0.98429,     0.98456,      0.9851,      0.9851,     0.98517,     0.98523,     0.98522,     0.98521,     0.98526,     0.98534,     0.98548,     0.98547,     0.98546,      0.9856,     0.98559,     0.98558,     0.98571,\n",
       "            0.98584,     0.98584,     0.98583,     0.98596,     0.98609,     0.98608,     0.98621,     0.98621,     0.98634,     0.98661,     0.98659,      0.9868,     0.98712,     0.98714,     0.98713,     0.98727,     0.98736,     0.98772,     0.98781,      0.9879,     0.98805,     0.98808,     0.98808,\n",
       "            0.98807,     0.98821,      0.9882,      0.9882,     0.98819,     0.98819,     0.98819,     0.98818,     0.98818,     0.98832,     0.98833,     0.98859,     0.98858,     0.98858,     0.98871,      0.9887,     0.98897,     0.98896,     0.98896,     0.98895,     0.98895,     0.98894,     0.98907,\n",
       "            0.98907,     0.98921,      0.9892,      0.9892,     0.98919,     0.98947,     0.98946,     0.98957,      0.9896,      0.9896,     0.98973,     0.98973,     0.98972,     0.98979,     0.98999,     0.98999,     0.98998,     0.98998,     0.99008,     0.99012,     0.99025,     0.99025,     0.99024,\n",
       "            0.99038,     0.99038,     0.99052,     0.99066,     0.99086,     0.99095,     0.99094,     0.99094,     0.99108,     0.99122,     0.99122,     0.99121,     0.99138,      0.9915,     0.99149,     0.99148,      0.9917,     0.99176,     0.99176,      0.9919,     0.99203,     0.99203,     0.99203,\n",
       "            0.99217,     0.99228,      0.9923,     0.99244,     0.99243,     0.99243,     0.99242,     0.99242,     0.99256,     0.99256,      0.9927,      0.9927,     0.99269,      0.9928,     0.99283,     0.99297,     0.99297,     0.99327,     0.99326,      0.9934,     0.99355,     0.99355,     0.99368,\n",
       "            0.99368,     0.99367,     0.99367,     0.99381,     0.99396,     0.99396,     0.99395,     0.99395,     0.99395,     0.99394,     0.99393,     0.99393,     0.99393,     0.99407,     0.99422,     0.99422,     0.99421,     0.99421,     0.99421,     0.99436,     0.99435,     0.99435,     0.99434,\n",
       "            0.99449,     0.99448,     0.99448,     0.99447,     0.99447,     0.99447,     0.99446,     0.99446,     0.99445,      0.9946,     0.99475,     0.99474,     0.99474,     0.99474,     0.99473,     0.99472,     0.99472,     0.99471,     0.99471,      0.9947,     0.99485,     0.99501,     0.99515,\n",
       "            0.99514,     0.99514,     0.99514,     0.99513,     0.99513,     0.99513,     0.99512,     0.99512,     0.99511,      0.9951,      0.9951,     0.99525,     0.99524,     0.99539,     0.99554,     0.99569,     0.99585,     0.99584,       0.996,     0.99599,     0.99599,     0.99599,     0.99598,\n",
       "            0.99597,     0.99596,     0.99596,     0.99612,     0.99611,     0.99611,      0.9961,      0.9961,     0.99609,     0.99625,     0.99641,     0.99641,      0.9964,      0.9964,     0.99639,     0.99639,     0.99638,     0.99637,     0.99637,     0.99636,     0.99636,     0.99652,     0.99652,\n",
       "            0.99651,     0.99667,     0.99667,     0.99666,     0.99665,     0.99664,     0.99664,     0.99663,     0.99663,     0.99662,     0.99662,     0.99661,      0.9966,     0.99677,     0.99693,     0.99693,     0.99726,     0.99743,     0.99759,     0.99758,     0.99758,     0.99757,     0.99757,\n",
       "            0.99756,     0.99755,     0.99755,     0.99754,     0.99754,     0.99771,      0.9977,      0.9977,     0.99769,     0.99768,     0.99768,     0.99767,     0.99767,     0.99766,     0.99766,     0.99766,     0.99765,     0.99764,     0.99763,     0.99762,     0.99762,     0.99761,      0.9976,\n",
       "            0.99759,     0.99758,     0.99757,     0.99757,     0.99756,     0.99755,     0.99755,     0.99773,     0.99791,     0.99809,     0.99808,     0.99808,     0.99826,     0.99826,     0.99825,     0.99824,     0.99824,     0.99823,     0.99822,     0.99822,     0.99841,      0.9986,      0.9986,\n",
       "            0.99859,     0.99858,     0.99858,     0.99857,     0.99856,     0.99876,     0.99875,     0.99875,     0.99874,     0.99874,     0.99873,     0.99873,     0.99872,     0.99871,     0.99892,     0.99891,     0.99891,      0.9989,     0.99889,     0.99888,     0.99887,     0.99886,     0.99886,\n",
       "            0.99908,      0.9993,      0.9993,     0.99953,     0.99953,     0.99952,     0.99952,     0.99952,     0.99951,     0.99951,      0.9995,      0.9995,     0.99949,     0.99949,     0.99948,     0.99948,     0.99947,     0.99947,     0.99946,     0.99946,     0.99945,     0.99944,     0.99972,\n",
       "            0.99971,     0.99971,     0.99971,      0.9997,      0.9997,     0.99969,     0.99969,     0.99968,     0.99968,     0.99967,     0.99967,     0.99966,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.98687,     0.98687,     0.98157,      0.9776,     0.97543,     0.97326,     0.97157,     0.96928,     0.96784,     0.96567,     0.96423,      0.9635,     0.96304,     0.96266,     0.96121,     0.95989,     0.95953,     0.95796,     0.95748,     0.95712,      0.9564,     0.95531,     0.95435,\n",
       "            0.95387,     0.95338,      0.9529,      0.9523,     0.95146,     0.95037,     0.95013,     0.94989,     0.94953,     0.94893,     0.94821,     0.94772,     0.94748,     0.94724,       0.947,     0.94688,     0.94628,     0.94609,      0.9458,     0.94556,     0.94543,     0.94507,     0.94483,\n",
       "            0.94483,     0.94435,     0.94407,     0.94363,     0.94327,     0.94303,     0.94266,     0.94242,     0.94182,     0.94146,     0.94122,      0.9411,     0.94074,     0.94025,     0.94013,     0.93977,     0.93946,     0.93917,     0.93917,     0.93905,     0.93884,     0.93857,     0.93833,\n",
       "            0.93809,     0.93797,     0.93776,     0.93761,     0.93712,     0.93664,     0.93628,     0.93628,     0.93592,     0.93532,     0.93512,     0.93471,     0.93459,     0.93423,     0.93423,     0.93423,     0.93387,     0.93363,     0.93351,     0.93279,     0.93267,     0.93231,     0.93219,\n",
       "            0.93206,     0.93158,     0.93158,     0.93158,     0.93134,      0.9311,     0.93062,      0.9305,      0.9299,     0.92966,     0.92941,     0.92933,     0.92894,     0.92881,     0.92845,     0.92809,     0.92773,     0.92749,     0.92725,     0.92725,     0.92725,     0.92713,     0.92702,\n",
       "            0.92701,     0.92689,     0.92676,     0.92676,     0.92664,      0.9264,     0.92604,     0.92592,      0.9258,     0.92537,     0.92508,     0.92507,     0.92484,     0.92448,     0.92448,     0.92436,     0.92411,     0.92411,     0.92387,     0.92364,     0.92339,     0.92327,     0.92316,\n",
       "            0.92279,     0.92248,     0.92231,     0.92231,     0.92207,     0.92159,     0.92159,     0.92134,     0.92122,     0.92106,     0.92089,     0.92062,     0.92038,     0.92014,     0.92014,     0.92014,     0.92009,     0.91978,     0.91966,     0.91936,      0.9193,     0.91929,     0.91906,\n",
       "            0.91879,     0.91845,     0.91833,     0.91833,     0.91827,     0.91797,     0.91785,     0.91779,     0.91737,     0.91725,     0.91725,     0.91725,     0.91713,     0.91677,     0.91677,     0.91677,     0.91665,     0.91617,      0.9158,     0.91568,      0.9156,     0.91538,     0.91532,\n",
       "             0.9152,      0.9152,     0.91448,     0.91425,       0.914,     0.91389,     0.91373,     0.91351,     0.91315,     0.91306,     0.91291,     0.91279,     0.91267,     0.91246,     0.91231,     0.91219,     0.91219,     0.91165,     0.91147,     0.91147,     0.91147,     0.91123,     0.91123,\n",
       "            0.91086,     0.91074,     0.91038,     0.91013,     0.91002,      0.9099,      0.9099,     0.90978,     0.90953,     0.90918,     0.90894,     0.90894,     0.90882,     0.90882,      0.9087,     0.90858,     0.90858,     0.90858,     0.90853,     0.90834,     0.90828,     0.90809,     0.90809,\n",
       "            0.90797,     0.90797,     0.90793,     0.90775,     0.90773,     0.90736,     0.90715,     0.90701,     0.90701,     0.90689,     0.90689,     0.90665,     0.90665,     0.90665,     0.90665,     0.90629,     0.90605,     0.90592,     0.90581,     0.90581,     0.90572,     0.90541,     0.90508,\n",
       "            0.90472,     0.90436,     0.90409,       0.904,     0.90388,     0.90368,     0.90364,     0.90348,     0.90341,     0.90328,     0.90328,     0.90306,     0.90279,     0.90255,     0.90255,      0.9023,     0.90207,     0.90192,     0.90171,     0.90103,     0.90075,     0.90011,     0.89971,\n",
       "            0.89933,     0.89906,      0.8987,     0.89846,     0.89846,     0.89822,     0.89798,     0.89786,     0.89786,     0.89737,     0.89725,     0.89713,     0.89713,     0.89713,     0.89677,      0.8965,     0.89631,     0.89602,     0.89593,     0.89577,     0.89519,     0.89488,      0.8948,\n",
       "             0.8945,     0.89448,       0.894,     0.89378,     0.89376,      0.8934,     0.89328,     0.89323,     0.89312,     0.89256,     0.89219,     0.89183,     0.89171,     0.89165,     0.89141,     0.89123,     0.89121,     0.89101,     0.89087,     0.89072,     0.89027,     0.89003,     0.88999,\n",
       "            0.88979,     0.88967,     0.88962,     0.88906,     0.88889,      0.8887,     0.88842,     0.88834,     0.88834,     0.88822,     0.88802,     0.88787,      0.8875,     0.88728,     0.88702,     0.88689,     0.88677,     0.88677,     0.88677,     0.88677,     0.88633,     0.88587,     0.88556,\n",
       "            0.88533,     0.88497,     0.88491,     0.88449,     0.88437,     0.88433,     0.88398,     0.88388,     0.88388,     0.88349,     0.88316,     0.88275,     0.88241,     0.88211,     0.88199,     0.88174,     0.88134,      0.8809,      0.8806,     0.88027,     0.88017,     0.88008,     0.87991,\n",
       "            0.87949,     0.87894,     0.87894,     0.87881,     0.87867,     0.87858,     0.87821,     0.87762,     0.87692,     0.87666,     0.87629,     0.87605,     0.87559,     0.87542,     0.87509,     0.87506,     0.87472,     0.87449,     0.87437,     0.87417,     0.87392,     0.87362,     0.87329,\n",
       "            0.87318,     0.87316,     0.87296,     0.87244,      0.8722,       0.872,     0.87177,     0.87156,      0.8709,     0.87081,     0.87068,     0.87063,     0.87027,     0.86991,     0.86989,     0.86943,     0.86933,     0.86891,     0.86859,     0.86848,     0.86798,     0.86787,     0.86775,\n",
       "            0.86732,     0.86719,      0.8669,     0.86678,     0.86678,      0.8663,      0.8663,     0.86612,     0.86593,     0.86566,     0.86545,     0.86495,     0.86477,     0.86449,     0.86377,     0.86365,     0.86357,     0.86329,     0.86295,     0.86266,     0.86256,     0.86193,     0.86172,\n",
       "            0.86136,     0.86095,     0.86056,     0.86028,     0.85991,     0.85968,     0.85927,     0.85919,     0.85864,     0.85842,       0.858,     0.85759,      0.8575,     0.85726,     0.85714,     0.85686,     0.85628,     0.85606,     0.85596,     0.85552,     0.85535,     0.85522,      0.8551,\n",
       "            0.85467,     0.85441,      0.8543,     0.85411,     0.85351,     0.85324,     0.85285,     0.85263,     0.85234,     0.85187,      0.8516,     0.85144,     0.85119,     0.85079,      0.8504,     0.85016,     0.85002,     0.84989,     0.84929,     0.84893,     0.84886,      0.8482,     0.84774,\n",
       "             0.8473,     0.84704,     0.84634,     0.84597,     0.84516,     0.84475,     0.84433,     0.84404,     0.84366,     0.84311,     0.84219,     0.84172,     0.84148,     0.84126,     0.84092,     0.84082,      0.8404,     0.84016,     0.83959,     0.83932,      0.8392,     0.83897,     0.83881,\n",
       "            0.83826,     0.83773,     0.83714,     0.83691,     0.83684,     0.83657,     0.83622,     0.83593,     0.83583,     0.83563,     0.83498,     0.83479,     0.83439,     0.83405,     0.83341,     0.83251,      0.8317,     0.83112,     0.83048,     0.83011,     0.82973,      0.8291,     0.82864,\n",
       "            0.82799,     0.82793,     0.82765,     0.82719,     0.82689,     0.82606,     0.82576,     0.82534,     0.82522,     0.82462,      0.8245,     0.82411,     0.82358,     0.82293,     0.82237,     0.82158,     0.82137,     0.82117,     0.82077,     0.82058,     0.81995,     0.81942,     0.81892,\n",
       "            0.81851,     0.81822,     0.81789,     0.81755,     0.81739,     0.81732,     0.81704,      0.8167,     0.81638,     0.81607,     0.81578,     0.81517,     0.81474,     0.81463,     0.81413,     0.81332,      0.8127,     0.81215,     0.81159,     0.81114,     0.81003,     0.80943,     0.80913,\n",
       "            0.80856,     0.80824,     0.80721,     0.80612,     0.80558,     0.80514,     0.80469,     0.80452,     0.80389,     0.80367,     0.80314,     0.80286,     0.80181,     0.80125,     0.80059,     0.80008,     0.79969,      0.7994,     0.79854,     0.79808,     0.79757,     0.79725,     0.79692,\n",
       "             0.7958,     0.79475,     0.79419,     0.79353,     0.79309,     0.79262,     0.79202,     0.79182,      0.7911,     0.78984,      0.7892,     0.78871,     0.78836,     0.78796,     0.78746,     0.78673,     0.78645,     0.78621,     0.78561,     0.78506,     0.78443,     0.78403,     0.78347,\n",
       "            0.78271,     0.78176,     0.78091,     0.78031,     0.77975,     0.77934,     0.77873,     0.77817,     0.77717,     0.77647,     0.77591,     0.77509,     0.77424,     0.77393,     0.77282,     0.77169,     0.77115,     0.77051,     0.77009,     0.76915,     0.76827,     0.76784,     0.76682,\n",
       "            0.76536,     0.76496,     0.76433,     0.76377,     0.76289,     0.76225,      0.7617,     0.76128,     0.75991,     0.75884,     0.75841,     0.75675,     0.75575,     0.75477,     0.75359,     0.75205,     0.75083,     0.75002,     0.74959,     0.74877,     0.74787,     0.74703,     0.74558,\n",
       "            0.74457,     0.74312,     0.74239,      0.7417,     0.74079,     0.73963,     0.73871,     0.73794,     0.73737,     0.73689,     0.73523,     0.73467,      0.7333,     0.73252,     0.73124,     0.73064,     0.72909,     0.72822,     0.72713,     0.72602,     0.72528,     0.72434,     0.72365,\n",
       "            0.72299,     0.72187,     0.72013,     0.71912,     0.71727,     0.71548,     0.71476,     0.71349,      0.7128,     0.71069,     0.70931,     0.70827,     0.70715,     0.70597,     0.70499,     0.70362,     0.70232,     0.70084,     0.69853,     0.69645,     0.69543,     0.69312,     0.69137,\n",
       "            0.68961,     0.68787,     0.68628,     0.68501,     0.68316,     0.68145,     0.67966,     0.67866,      0.6761,     0.67469,     0.67253,     0.67107,     0.66991,     0.66865,     0.66745,     0.66648,     0.66456,     0.66269,     0.66018,     0.65728,     0.65591,     0.65346,     0.65106,\n",
       "            0.64903,     0.64645,      0.6441,     0.64237,     0.64078,     0.63792,     0.63648,     0.63439,     0.63154,     0.62968,     0.62723,     0.62499,     0.62255,     0.62029,     0.61871,     0.61615,     0.61482,     0.61245,     0.60961,     0.60734,     0.60489,     0.60276,     0.60046,\n",
       "             0.5967,     0.59336,     0.59102,      0.5879,     0.58539,     0.58299,     0.57972,     0.57674,     0.57367,     0.57163,     0.56934,     0.56646,     0.56386,       0.561,     0.55711,     0.55279,     0.54947,     0.54528,     0.54121,     0.53709,     0.53409,      0.5292,     0.52542,\n",
       "            0.52216,      0.5195,     0.51627,      0.5133,     0.50807,     0.50469,     0.50083,      0.4966,     0.49304,     0.48847,     0.48429,     0.47977,      0.4745,     0.47064,     0.46592,     0.46173,     0.45773,     0.45339,     0.44922,     0.44428,     0.43898,     0.43221,     0.42764,\n",
       "            0.42194,     0.41789,     0.41084,     0.40549,     0.39883,      0.3929,     0.38865,     0.38184,     0.37644,     0.37006,     0.36254,     0.35756,     0.35197,       0.346,     0.33887,     0.33209,     0.32634,     0.31931,     0.31308,     0.30564,     0.29934,     0.29318,     0.28628,\n",
       "            0.27963,     0.27243,     0.26634,     0.25986,     0.25417,     0.24822,     0.24158,     0.23595,     0.22937,     0.22229,     0.21538,     0.21096,     0.20415,     0.19747,     0.19142,     0.18563,     0.17849,     0.17278,     0.16744,     0.15996,     0.15541,     0.14951,     0.14363,\n",
       "            0.13826,     0.13317,     0.12712,     0.12089,     0.11453,     0.10972,     0.10471,    0.098915,    0.095358,     0.09014,    0.085015,     0.08008,    0.075905,    0.071991,    0.067724,    0.063729,    0.059533,    0.055562,    0.050489,    0.046091,    0.042806,     0.03986,    0.036738,\n",
       "           0.033325,     0.03139,    0.028638,     0.02615,    0.024471,    0.022871,    0.021251,    0.020056,    0.017754,    0.016168,    0.014572,    0.013202,    0.011842,    0.011438,    0.010048,   0.0090739,   0.0083552,   0.0073198,   0.0069044,    0.006078,   0.0053638,   0.0043924,   0.0033443,\n",
       "           0.002664,   0.0022705,   0.0021226,   0.0019231,   0.0016714,   0.0015674,   0.0011563,   0.0010537,  0.00083413,   0.0008074,  0.00078068,  0.00075395,  0.00072723,  0.00067956,  0.00062764,  0.00045921,  0.00036942,   0.0001512,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.6829087906785187)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.65202])\n",
       "names: {0: 'person'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.9587688779842266), 'metrics/recall(B)': np.float64(0.8963054248675733), 'metrics/mAP50(B)': np.float64(0.9608690057058739), 'metrics/mAP50-95(B)': np.float64(0.652024322342146), 'fitness': np.float64(0.6829087906785187)}\n",
       "save_dir: WindowsPath('runs/detect/my_yolov8_exp52')\n",
       "speed: {'preprocess': 0.11117923766491374, 'inference': 1.6538470978857713, 'loss': 0.0006095581846860317, 'postprocess': 0.7699114929159993}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.94  Python-3.12.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Projects\\multimodal\\datasets\\llvip_fused_yuv\\labels\\test.cache... 3463 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3463/3463 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 217/217 [00:19<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3463       8302      0.959      0.896      0.961      0.652\n",
      "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\final_test3\u001b[0m\n",
      "mAP@0.5: 0.9608690057058739\n"
     ]
    }
   ],
   "source": [
    "best_model = YOLO(\"runs/detect/my_yolov8_exp5/weights/best.pt\") \n",
    "metrics = best_model.val(\n",
    "    device=0,\n",
    "    name=\"final_test\"\n",
    ")\n",
    "print(f\"mAP@0.5: {metrics.box.map50}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
