{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python numpy pandas xmltodict tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm.auto import tqdm  # Automatycznie wykrywa środowisko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dirs():\n",
    "    \"\"\"Tworzy strukturę folderów dla danych po fuzji\"\"\"\n",
    "    os.makedirs(\"datasets/llvip_fused_yuv/images/train\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/llvip_fused_yuv/images/test\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/llvip_fused_yuv/labels/train\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/llvip_fused_yuv/labels/test\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_images_yuv(rgb_path, ir_path, output_path):\n",
    "    \"\"\"Łączy obrazy RGB i IR w przestrzeni YUV\"\"\"\n",
    "    # Wczytaj obrazy\n",
    "    rgb_img = cv2.imread(rgb_path)\n",
    "    ir_img = cv2.imread(ir_path, cv2.IMREAD_GRAYSCALE)  # IR jako 1-kanałowy\n",
    "    \n",
    "    # Konwersja RGB → YUV\n",
    "    yuv = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2YUV)\n",
    "    y, u, v = cv2.split(yuv)\n",
    "    \n",
    "    # Dopasuj IR do rozmiaru Y i znormalizuj\n",
    "    ir_resized = cv2.resize(ir_img, (y.shape[1], y.shape[0]))\n",
    "    ir_normalized = cv2.normalize(ir_resized, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    # Fuzja i konwersja do RGB\n",
    "    fused_yuv = cv2.merge([ir_normalized, u, v])\n",
    "    fused_rgb = cv2.cvtColor(fused_yuv, cv2.COLOR_YUV2BGR)\n",
    "    \n",
    "    # Zapisz wynik\n",
    "    cv2.imwrite(output_path, fused_rgb)\n",
    "\n",
    "def convert_voc_to_yolo(xml_path, output_txt_path):\n",
    "    \"\"\"Konwertuje adnotacje z formatu VOC do YOLO\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Pobierz rozmiar obrazu\n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "    \n",
    "    # Przygotuj linie dla YOLO\n",
    "    yolo_lines = []\n",
    "    for obj in root.findall('object'):\n",
    "        class_name = obj.find('name').text.lower()\n",
    "        class_idx = 0  # Zakładamy, że wszystkie obiekty to \"person\"\n",
    "        \n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text)\n",
    "        ymin = int(bbox.find('ymin').text)\n",
    "        xmax = int(bbox.find('xmax').text)\n",
    "        ymax = int(bbox.find('ymax').text)\n",
    "        \n",
    "        # Konwersja do formatu YOLO\n",
    "        x_center = (xmin + xmax) / 2 / width\n",
    "        y_center = (ymin + ymax) / 2 / height\n",
    "        w = (xmax - xmin) / width\n",
    "        h = (ymax - ymin) / height\n",
    "        \n",
    "        yolo_lines.append(f\"{class_idx} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "    \n",
    "    # Zapisz do pliku\n",
    "    with open(output_txt_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(yolo_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_dataset():\n",
    "    create_dirs()\n",
    "    \n",
    "    for split in [\"train\", \"test\"]:\n",
    "        rgb_dir = os.path.join(\"LLVIP/visible\", split)\n",
    "        ir_dir = os.path.join(\"LLVIP/infrared\", split)\n",
    "        \n",
    "        # Przetwórz wszystkie obrazy w folderze visible\n",
    "        for img_name in tqdm(os.listdir(rgb_dir), desc=f\"Przetwarzanie {split}\"):\n",
    "            rgb_path = os.path.join(rgb_dir, img_name)\n",
    "            \n",
    "            # Szukaj odpowiadającego IR po nazwie (ignoruj rozszerzenie)\n",
    "            base_name = os.path.splitext(img_name)[0]\n",
    "            ir_candidates = [\n",
    "                f for f in os.listdir(ir_dir) \n",
    "                if os.path.splitext(f)[0] == base_name\n",
    "            ]\n",
    "            \n",
    "            if not ir_candidates:\n",
    "                print(f\"Brak IR dla {img_name} – pomijam.\")\n",
    "                continue\n",
    "                \n",
    "            # Jeśli wiele pasujących IR, weź pierwszy\n",
    "            ir_filename = ir_candidates[0]\n",
    "            ir_path = os.path.join(ir_dir, ir_filename)\n",
    "            \n",
    "            # Ścieżki wynikowe\n",
    "            fused_img_path = os.path.join(\"datasets/llvip_fused_yuv/images\", split, img_name)\n",
    "            txt_path = os.path.join(\"datasets/llvip_fused_yuv/labels\", split, \n",
    "                                   os.path.splitext(img_name)[0] + \".txt\")\n",
    "            \n",
    "            # Fuzja obrazów\n",
    "            fuse_images_yuv(rgb_path, ir_path, fused_img_path)\n",
    "            \n",
    "            # Konwersja adnotacji\n",
    "            xml_path = os.path.join(\"Annotations\", os.path.splitext(img_name)[0] + \".xml\")\n",
    "            if os.path.exists(xml_path):\n",
    "                convert_voc_to_yolo(xml_path, txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"CUDA dostępne: {torch.cuda.is_available()}\")\n",
    "print(f\"Wersja CUDA: {torch.version.cuda}\")\n",
    "print(f\"Nazwa GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "data_yaml = os.path.abspath(\"./datasets/llvip_fused_yuv/data.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "# Ścieżki bezwzględne\n",
    "data_yaml = os.path.abspath(\"./datasets/llvip_fused_yuv/data.yaml\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Wymuś użycie GPU o indeksie 0\n",
    "command = [\n",
    "    sys.executable, \"yolov5/train.py\",\n",
    "    \"--img\", \"640\",\n",
    "    \"--batch\", \"16\",\n",
    "    \"--epochs\", \"25\",\n",
    "    \"--data\", data_yaml,\n",
    "    \"--weights\", \"yolov5s.pt\",\n",
    "    \"--device\", \"0\",\n",
    "    \"--name\", \"fused_yuv_exp\",\n",
    "    \"--workers\", \"4\"  # Zmniejsz jeśli masz mniej niż 4 rdzenie\n",
    "]\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        command,\n",
    "        check=True,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        encoding='utf-8',\n",
    "        errors='replace'\n",
    "    )\n",
    "    print(\"Output:\")\n",
    "    print(result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error (code {e.returncode}):\")\n",
    "    print(e.stderr)\n",
    "    print(e.stdout)\n",
    "except Exception as e:\n",
    "    print(f\"Critical error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "\n",
    "command = [\n",
    "    sys.executable, \n",
    "    \"yolov5/train.py\",\n",
    "    \"--img\", \"640\",\n",
    "    \"--batch\", \"16\",\n",
    "    \"--epochs\", \"50\",\n",
    "    \"--data\", data_yaml,\n",
    "    \"--weights\", \"yolov5s.pt\",\n",
    "    \"--device\", \"0\",\n",
    "    \"--name\", \"fused_yuv_exp\",\n",
    "    \"--workers\", \"4\"\n",
    "]\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    command,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1,\n",
    "    encoding='utf-8',  # Wymuś kodowanie UTF-8\n",
    "    errors='replace'   # Zastąp błędne znaki symbolem �\n",
    ")\n",
    "\n",
    "# Wyświetlaj logi na żywo\n",
    "while True:\n",
    "    line = process.stdout.readline()\n",
    "    if not line and process.poll() is not None:\n",
    "        break\n",
    "    if line:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Konfiguracja ścieżek\n",
    "log_dir = \"training_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Pliki wyjściowe\n",
    "log_file = os.path.join(log_dir, f\"train_log_{timestamp}.txt\")\n",
    "csv_file = os.path.join(log_dir, f\"metrics_{timestamp}.csv\")\n",
    "\n",
    "# Nagłówki CSV\n",
    "csv_headers = [\"epoch\", \"gpu_mem\", \"box_loss\", \"obj_loss\", \"cls_loss\", \"labels\", \"mAP@0.5\", \"mAP@0.5:0.95\"]\n",
    "\n",
    "# Regular expressions\n",
    "progress_pattern = re.compile(r\"(\\d+/\\d+).*?(\\d+\\.\\d+)(?=it/s)\")  # Wykrywa linie z postępem\n",
    "metrics_pattern = re.compile(\n",
    "    r\"\\s*(\\d+)\\s+(\\d+\\.?\\d*)G\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\"\n",
    ")\n",
    "\n",
    "command = [\n",
    "    sys.executable, \"-u\", \"yolov5/train.py\",\n",
    "    \"--img\", \"640\",\n",
    "    \"--batch\", \"16\",\n",
    "    \"--epochs\", \"25\",\n",
    "    \"--data\", os.path.abspath(\"./datasets/llvip_fused_yuv/data.yaml\"),\n",
    "    \"--weights\", \"yolov5s.pt\",\n",
    "    \"--device\", \"0\",\n",
    "    \"--name\", \"fused_yuv_exp\",\n",
    "    \"--workers\", \"4\"\n",
    "]\n",
    "\n",
    "with open(log_file, \"w\", encoding=\"utf-8\") as log_f, \\\n",
    "     open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as csv_f:\n",
    "\n",
    "    writer = csv.DictWriter(csv_f, fieldnames=csv_headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        command,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        bufsize=1,\n",
    "        encoding=\"utf-8\",\n",
    "        errors=\"replace\",\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    current_epoch = 0\n",
    "    last_progress = \"\"  # Przechowuje ostatnią linię postępu\n",
    "    \n",
    "    while True:\n",
    "        line = process.stdout.readline()\n",
    "        if not line:\n",
    "            if process.poll() is not None: break\n",
    "            continue\n",
    "            \n",
    "        # Zawsze zapisuj do logu\n",
    "        log_f.write(line)\n",
    "        log_f.flush()\n",
    "\n",
    "        # Obsługa wyświetlania\n",
    "        if progress_pattern.search(line):\n",
    "            # Czyść tylko linię postępu\n",
    "            clear_output(wait=True)\n",
    "            print(line.strip(), end=\"\\r\")\n",
    "            last_progress = line.strip()\n",
    "        else:\n",
    "            # Dla pozostałych linii - nowa linia\n",
    "            print(line.strip())\n",
    "        \n",
    "        # Parsowanie metryk\n",
    "        try:\n",
    "            if metrics_pattern.search(line):\n",
    "                match = metrics_pattern.search(line)\n",
    "                metrics = {\n",
    "                    \"epoch\": current_epoch,\n",
    "                    \"gpu_mem\": float(match.group(2).replace('G', '')),\n",
    "                    \"box_loss\": float(match.group(3)),\n",
    "                    \"obj_loss\": float(match.group(4)),\n",
    "                    \"cls_loss\": float(match.group(5)),\n",
    "                    \"labels\": int(match.group(6)),\n",
    "                    \"mAP@0.5\": float(match.group(7)),\n",
    "                    \"mAP@0.5:0.95\": float(match.group(8))\n",
    "                }\n",
    "                writer.writerow(metrics)\n",
    "                csv_f.flush()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Błąd parsowania: {str(e)}\")\n",
    "\n",
    "print(f\"\\nTrening zakończony! Ostatni postęp: {last_progress}\")\n",
    "print(f\"Pełny log: {log_file}\")\n",
    "print(f\"Metryki CSV: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "command = [\n",
    "    sys.executable, \n",
    "    \"yolov5/train.py\",\n",
    "    \"--img\", \"640\",\n",
    "    \"--batch\", \"16\",\n",
    "    \"--epochs\", \"50\",\n",
    "    \"--data\", \"datasets/llvip_fused_yuv/data.yaml\",\n",
    "    \"--weights\", \"yolov5s.pt\",\n",
    "    \"--device\", \"0\"\n",
    "]\n",
    "\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1myolov5\\runs\\train\\fused_yuv_exp\u001b[0m\n",
      "\n",
      "Trening zakończony!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "from time import time\n",
    "\n",
    "def format_metrics(metrics):\n",
    "    \"\"\"Formatuje metryki w czytelny sposób\"\"\"\n",
    "    return (\n",
    "        f\"Epoka: {metrics['epoch']:>2}/{metrics['epochs']} | \"\n",
    "        f\"Loss: {metrics['box_loss']:.3f} | \"\n",
    "        f\"mAP@0.5: {metrics['mAP@0.5']:.3f} | \"\n",
    "        f\"GPU: {metrics['gpu_mem']:.1f}GB | \"\n",
    "        f\"Czas: {metrics['time']:>5}\"\n",
    "    )\n",
    "\n",
    "def train_yolo():\n",
    "    command = [\n",
    "        sys.executable, \n",
    "        \"yolov5/train.py\",\n",
    "        \"--img\", \"640\",\n",
    "        \"--batch\", \"16\",\n",
    "        \"--epochs\", \"50\",\n",
    "        \"--data\", \"datasets/llvip_fused_yuv/data.yaml\",\n",
    "        \"--weights\", \"yolov5s.pt\",\n",
    "        \"--device\", \"0\",\n",
    "        \"--name\", \"fused_yuv_exp\",\n",
    "        \"--exist-ok\"\n",
    "    ]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        command,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        bufsize=1,\n",
    "        text=True,\n",
    "        encoding=\"utf-8\",\n",
    "        errors=\"replace\"\n",
    "    )\n",
    "\n",
    "    # Wzorce regex do parsowania logów\n",
    "    epoch_pattern = re.compile(r\"(\\d+)/(\\d+).*?(\\d+\\.\\d+)it/s.*?(\\d+:\\d+<.*?) \")\n",
    "    metric_pattern = re.compile(\n",
    "        r\"(\\d+)\\s+(\\d+\\.\\d+)G\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+\\d+\\s+\\d+\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\"\n",
    "    )\n",
    "\n",
    "    current_metrics = {}\n",
    "    last_update = time()\n",
    "    \n",
    "    while True:\n",
    "        line = process.stdout.readline()\n",
    "        if not line:\n",
    "            if process.poll() is not None:\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        # Parsuj metryki\n",
    "        if metric_match := metric_pattern.search(line):\n",
    "            current_metrics.update({\n",
    "                \"epoch\": int(metric_match.group(1)),\n",
    "                \"gpu_mem\": float(metric_match.group(2)),\n",
    "                \"box_loss\": float(metric_match.group(3)),\n",
    "                \"obj_loss\": float(metric_match.group(4)),\n",
    "                \"cls_loss\": float(metric_match.group(5)),\n",
    "                \"mAP@0.5\": float(metric_match.group(6)),\n",
    "                \"mAP@0.5:0.95\": float(metric_match.group(7)),\n",
    "                \"epochs\": 30\n",
    "            })\n",
    "\n",
    "        # Aktualizuj postęp co 0.5 sekundy\n",
    "        if (time() - last_update) > 0.5 and (progress_match := epoch_pattern.search(line)):\n",
    "            current_metrics[\"time\"] = progress_match.group(4)\n",
    "            clear_output(wait=True)\n",
    "            print(format_metrics(current_metrics))\n",
    "            last_update = time()\n",
    "\n",
    "        # Wyświetl ważne komunikaty\n",
    "        if any(x in line for x in [\"Saved model\", \"Results saved to\", \"Best mAP\"]):\n",
    "            clear_output(wait=True)\n",
    "            print(line.strip())\n",
    "\n",
    "    print(\"\\nTrening zakończony!\")\n",
    "\n",
    "# Uruchom trening\n",
    "train_yolo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
