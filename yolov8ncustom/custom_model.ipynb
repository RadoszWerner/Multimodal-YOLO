{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c9dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "from ultralytics.utils.torch_utils import initialize_weights\n",
    "\n",
    "class MultiModalYOLO(DetectionModel):\n",
    "    def __init__(self, cfg=\"yolov8n.yaml\"):\n",
    "        # Najpierw inicjalizujemy DetectionModel\n",
    "        super().__init__(cfg)\n",
    "        \n",
    "        # Zachowaj oryginalny backbone dla RGB\n",
    "        self.backbone_rgb = self.model.backbone\n",
    "        \n",
    "        # Stwórz nowy backbone dla IR z modyfikacjami\n",
    "        self.backbone_ir = self._create_ir_backbone()\n",
    "        \n",
    "        # Warstwy fuzji\n",
    "        self.fusion_convs = nn.ModuleList([\n",
    "            nn.Conv2d(2 * ch, ch, kernel_size=1) for ch in self.backbone_rgb.out_channels\n",
    "        ])\n",
    "\n",
    "    def _create_ir_backbone(self):\n",
    "        # Klonujemy architekturę backbone'u\n",
    "        backbone_ir = self.model.backbone.__class__()\n",
    "        \n",
    "        # Modyfikujemy pierwszą warstwę Conv2d na 1 kanał wejściowy\n",
    "        first_conv = None\n",
    "        for name, module in backbone_ir.named_children():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                first_conv = module\n",
    "                break\n",
    "                \n",
    "        if first_conv:\n",
    "            new_conv = nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=first_conv.out_channels,\n",
    "                kernel_size=first_conv.kernel_size,\n",
    "                stride=first_conv.stride,\n",
    "                padding=first_conv.padding,\n",
    "                bias=first_conv.bias is not None\n",
    "            )\n",
    "            initialize_weights(new_conv)\n",
    "            backbone_ir._modules[name] = new_conv\n",
    "            \n",
    "        return backbone_ir\n",
    "\n",
    "    def forward(self, x_rgb, x_ir=None):\n",
    "        # Obsługa przypadku inicjalizacji przez parent class\n",
    "        if x_ir is None:\n",
    "            x_ir = torch.zeros_like(x_rgb[:, :1])  # Zachowaj batch i rozdzielczość\n",
    "            \n",
    "        # Ekstrakcja cech\n",
    "        p3_rgb, p4_rgb, p5_rgb = self.backbone_rgb(x_rgb)\n",
    "        p3_ir, p4_ir, p5_ir = self.backbone_ir(x_ir)\n",
    "        \n",
    "        # Fuzja\n",
    "        p3 = self.fusion_convs[0](torch.cat([p3_rgb, p3_ir], dim=1))\n",
    "        p4 = self.fusion_convs[1](torch.cat([p4_rgb, p4_ir], dim=1))\n",
    "        p5 = self.fusion_convs[2](torch.cat([p5_rgb, p5_ir], dim=1))\n",
    "        \n",
    "        return self.model.head(self.model.neck([p3, p4, p5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc2089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiModalYOLO' object has no attribute 'backbone_rgb'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Inicjalizacja modelu\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model = \u001b[43mMultiModalYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Test forward pass z przykładowymi danymi\u001b[39;00m\n\u001b[32m     11\u001b[39m x_rgb = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m640\u001b[39m, \u001b[32m640\u001b[39m).to(device)  \u001b[38;5;66;03m# RGB (3 kanały)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mMultiModalYOLO.__init__\u001b[39m\u001b[34m(self, cfg)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg=\u001b[33m\"\u001b[39m\u001b[33myolov8n.yaml\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Najpierw inicjalizujemy DetectionModel\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Zachowaj oryginalny backbone dla RGB\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mself\u001b[39m.backbone_rgb = \u001b[38;5;28mself\u001b[39m.model.backbone\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv1\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:352\u001b[39m, in \u001b[36mDetectionModel.__init__\u001b[39m\u001b[34m(self, cfg, ch, nc, verbose)\u001b[39m\n\u001b[32m    349\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward(x)[\u001b[33m\"\u001b[39m\u001b[33mone2many\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward(x)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, (Segment, YOLOESegment, Pose, OBB)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward(x)\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m m.stride = torch.tensor([s / x.shape[-\u001b[32m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m])  \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;28mself\u001b[39m.stride = m.stride\n\u001b[32m    354\u001b[39m m.bias_init()  \u001b[38;5;66;03m# only run once\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv1\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:350\u001b[39m, in \u001b[36mDetectionModel.__init__.<locals>._forward\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.end2end:\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward(x)[\u001b[33m\"\u001b[39m\u001b[33mone2many\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward(x)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, (Segment, YOLOESegment, Pose, OBB)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mMultiModalYOLO.forward\u001b[39m\u001b[34m(self, x_rgb, x_ir)\u001b[39m\n\u001b[32m     50\u001b[39m     x_ir = torch.zeros_like(x_rgb[:, :\u001b[32m1\u001b[39m])  \u001b[38;5;66;03m# Zachowaj batch i rozdzielczość\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Ekstrakcja cech\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m p3_rgb, p4_rgb, p5_rgb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone_rgb\u001b[49m(x_rgb)\n\u001b[32m     54\u001b[39m p3_ir, p4_ir, p5_ir = \u001b[38;5;28mself\u001b[39m.backbone_ir(x_ir)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Fuzja\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'MultiModalYOLO' object has no attribute 'backbone_rgb'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Konfiguracja\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = MultiModalYOLO().to(device)\n",
    "\n",
    "# Test forward pass z przykładowymi danymi\n",
    "x_rgb = torch.randn(1, 3, 640, 640).to(device)  # RGB (3 kanały)\n",
    "x_ir = torch.randn(1, 1, 640, 640).to(device)   # IR (1 kanał)\n",
    "\n",
    "# Test 1: Zwykły forward\n",
    "outputs = model(x_rgb, x_ir)\n",
    "print([t.shape for t in outputs])\n",
    "\n",
    "# Test 2: Symulacja inicjalizacji przez DetectionModel (tylko 1 tensor)\n",
    "dummy_input = torch.randn(1, 3, 640, 640).to(device)  # Na potrzeby inicjalizacji\n",
    "try:\n",
    "    model(dummy_input)  # Wykorzysta wewnętrznie x_ir = zeros\n",
    "    print(\"Inicjalizacja udana!\")\n",
    "except Exception as e:\n",
    "    print(f\"Błąd: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
