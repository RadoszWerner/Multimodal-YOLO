{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a415de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "def convert_voc_to_yolo(xml_path, output_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    img_width = int(size.find('width').text)\n",
    "    img_height = int(size.find('height').text)\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        for obj in root.findall('object'):\n",
    "            class_id = 0  # Dla klasy 'person', dostosuj jeśli masz inne klasy\n",
    "            bbox = obj.find('bndbox')\n",
    "            xmin = float(bbox.find('xmin').text)\n",
    "            ymin = float(bbox.find('ymin').text)\n",
    "            xmax = float(bbox.find('xmax').text)\n",
    "            ymax = float(bbox.find('ymax').text)\n",
    "            \n",
    "            # Obliczenie znormalizowanych współrzędnych\n",
    "            x_center = (xmin + xmax) / 2 / img_width\n",
    "            y_center = (ymin + ymax) / 2 / img_height\n",
    "            width = (xmax - xmin) / img_width\n",
    "            height = (ymax - ymin) / img_height\n",
    "            \n",
    "            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# Przykład użycia dla folderu z adnotacjami\n",
    "annotations_dir = 'LLVIP/Annotations'  # Zmień na swój folder\n",
    "for xml_file in os.listdir(annotations_dir):\n",
    "    if xml_file.endswith('.xml'):\n",
    "        xml_path = os.path.join(annotations_dir, xml_file)\n",
    "        txt_path = xml_path.replace('.xml', '.txt')\n",
    "        convert_voc_to_yolo(xml_path, txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from ultralytics.utils.loss import v8DetectionLoss\n",
    "\n",
    "# # Ustawienie urządzenia\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Przygotowanie modelu\n",
    "# model = custom_model.to(device)\n",
    "# model.train()\n",
    "# loss_fn = v8DetectionLoss(model)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Pętla treningowa\n",
    "# num_epochs = 50\n",
    "# best_loss = float('inf')\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     for batch in train_loader:\n",
    "#         img_rgb, img_ir, targets = batch\n",
    "#         img_rgb = img_rgb.to(device)\n",
    "#         img_ir = img_ir.to(device)\n",
    "#         targets = [t.to(device) for t in targets]\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(img_rgb, img_ir)\n",
    "#         loss = loss_fn(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f\"Epoka {epoch+1}/{num_epochs}, Strata: {loss.item()}\")\n",
    "#     # Zapisz model, jeśli strata jest lepsza\n",
    "#     if loss.item() < best_loss:\n",
    "#         best_loss = loss.item()\n",
    "#         torch.save(model.state_dict(), 'best_model.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
