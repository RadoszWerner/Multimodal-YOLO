{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch\n",
    "from ultralytics.nn.modules import Concat, C2f, Conv\n",
    "\n",
    "\n",
    "pretrained_model = YOLO('yolov8m.pt').model\n",
    "backbone = nn.Sequential(*list(pretrained_model.model.children())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBackbone(nn.Module):\n",
    "    def __init__(self, layers, out_idx=[2, 4, 9]):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.out_idx = out_idx\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if idx in self.out_idx:\n",
    "                outputs.append(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb292dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 3, 3, 3])\n",
      "torch.Size([48, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "backbone_rgb = CustomBackbone(backbone)\n",
    "backbone_ir = copy.deepcopy(backbone_rgb)\n",
    "\n",
    "backbone_ir.layers[0].conv = nn.Conv2d(1, 48, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "print(backbone_rgb.layers[0].conv.weight.shape)\n",
    "print(backbone_ir.layers[0].conv.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNeck(nn.Module):\n",
    "    def __init__(self, fused_channels=[96, 192, 576]):\n",
    "        super().__init__()\n",
    "        # Inicjalizacja warstw taka sama jak wcześniej\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.c2f_p4 = C2f(fused_channels[2] + fused_channels[1], 384, n=2)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.c2f_p3 = C2f(384 + fused_channels[0], 192, n=2)\n",
    "        self.conv_p3 = Conv(192, 192, k=3, s=2)\n",
    "        self.c2f_d1 = C2f(192 + 384, 384, n=2)\n",
    "        self.conv_p4 = Conv(384, 384, k=3, s=2)\n",
    "        self.c2f_d2 = C2f(384 + 576, 576, n=2)\n",
    "\n",
    "    def forward(self, fused_features):\n",
    "        p3, p4, p5 = fused_features\n",
    "        print(f\"\\nWejście do necku: P3={p3.shape}, P4={p4.shape}, P5={p5.shape}\")\n",
    "\n",
    "        # Top-down path (P5 -> P4)\n",
    "        x = self.upsample1(p5)\n",
    "        print(f\"Po upsample1: {x.shape}\")\n",
    "        x = torch.cat([x, p4], 1)\n",
    "        print(f\"Po concat z P4: {x.shape}\")\n",
    "        x_p4 = self.c2f_p4(x)\n",
    "        print(f\"Po c2f_p4: {x_p4.shape}\")\n",
    "\n",
    "        # Top-down path (P4 -> P3)\n",
    "        x = self.upsample2(x_p4)\n",
    "        print(f\"Po upsample2: {x.shape}\")\n",
    "        x = torch.cat([x, p3], 1)\n",
    "        print(f\"Po concat z P3: {x.shape}\")\n",
    "        x_p3 = self.c2f_p3(x)\n",
    "        print(f\"Po c2f_p3: {x_p3.shape}\")\n",
    "\n",
    "        # Bottom-up path (P3 -> P4)\n",
    "        x = self.conv_p3(x_p3)\n",
    "        print(f\"Po conv_p3 (downsample): {x.shape}\")\n",
    "        x = torch.cat([x, x_p4], 1)\n",
    "        print(f\"Po concat z x_p4: {x.shape}\")\n",
    "        x_d1 = self.c2f_d1(x)\n",
    "        print(f\"Po c2f_d1: {x_d1.shape}\")\n",
    "\n",
    "        # Bottom-up path (P4 -> P5)\n",
    "        x = self.conv_p4(x_d1)\n",
    "        print(f\"Po conv_p4 (downsample): {x.shape}\")\n",
    "        x = torch.cat([x, p5], 1)\n",
    "        print(f\"Po concat z P5: {x.shape}\")\n",
    "        x_d2 = self.c2f_d2(x)\n",
    "        print(f\"Po c2f_d2: {x_d2.shape}\")\n",
    "\n",
    "        return [x_p3, x_d1, x_d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c59393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomYOLO(nn.Module):\n",
    "    def __init__(self, pretrained_model, backbone_rgb, backbone_ir):\n",
    "        super().__init__()\n",
    "        self.backbone_rgb = backbone_rgb\n",
    "        self.backbone_ir = backbone_ir\n",
    "        \n",
    "        # Inicjalizacja necku z odpowiednimi parametrami\n",
    "        self.neck_head = CustomNeck(fused_channels=[96, 192, 576])\n",
    "        \n",
    "        # Przeniesienie warstwy Detect z pretrenowanego modelu\n",
    "        self.detect = copy.deepcopy(pretrained_model.model[-1])\n",
    "        \n",
    "    def forward(self, x_rgb, x_ir):\n",
    "        # Ekstrakcja cech\n",
    "        features_rgb = self.backbone_rgb(x_rgb)\n",
    "        features_ir = self.backbone_ir(x_ir)\n",
    "        \n",
    "        # Fuzja przez sumowanie\n",
    "        fused = [f_rgb + f_ir for f_rgb, f_ir in zip(features_rgb, features_ir)]\n",
    "        \n",
    "        # Przetwarzanie przez neck\n",
    "        neck_outputs = self.neck_head(fused)\n",
    "        \n",
    "        # Detekcja\n",
    "        return self.detect(neck_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wejście do necku: P3=torch.Size([1, 192, 80, 80]), P4=torch.Size([1, 384, 40, 40]), P5=torch.Size([1, 576, 20, 20])\n",
      "Po upsample1: torch.Size([1, 576, 40, 40])\n",
      "Po concat z P4: torch.Size([1, 960, 40, 40])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [384, 768, 1, 1], expected input[1, 960, 40, 40] to have 768 channels, but got 960 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m x_ir = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m640\u001b[39m, \u001b[32m640\u001b[39m)\n\u001b[32m      5\u001b[39m model = CustomYOLO(pretrained_model, backbone_rgb, backbone_ir)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_rgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_ir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Sprawdzenie kształtów\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m outputs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mCustomYOLO.forward\u001b[39m\u001b[34m(self, x_rgb, x_ir)\u001b[39m\n\u001b[32m     19\u001b[39m fused = [f_rgb + f_ir \u001b[38;5;28;01mfor\u001b[39;00m f_rgb, f_ir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(features_rgb, features_ir)]\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Przetwarzanie przez neck\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m neck_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mneck_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfused\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Detekcja\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.detect(neck_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mCustomNeck.forward\u001b[39m\u001b[34m(self, fused_features)\u001b[39m\n\u001b[32m     21\u001b[39m x = torch.cat([x, p4], \u001b[32m1\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPo concat z P4: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m x_p4 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mc2f_p4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPo c2f_p4: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_p4.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Top-down path (P4 -> P3)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:300\u001b[39m, in \u001b[36mC2f.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    299\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     y = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m.chunk(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m    301\u001b[39m     y.extend(m(y[-\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.m)\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv2(torch.cat(y, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:79\u001b[39m, in \u001b[36mConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Apply convolution, batch normalization and activation to input tensor.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m \u001b[33;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28mself\u001b[39m.bn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [384, 768, 1, 1], expected input[1, 960, 40, 40] to have 768 channels, but got 960 channels instead"
     ]
    }
   ],
   "source": [
    "# Przykładowe dane wejściowe\n",
    "x_rgb = torch.randn(1, 3, 640, 640)\n",
    "x_ir = torch.randn(1, 1, 640, 640)\n",
    "\n",
    "model = CustomYOLO(pretrained_model, backbone_rgb, backbone_ir)\n",
    "outputs = model(x_rgb, x_ir)\n",
    "\n",
    "# Sprawdzenie kształtów\n",
    "for out in outputs:\n",
    "    print(out.shape)  # Powinno być (batch, num_anchors, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9be5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "WALIDACJA KSZTAŁTÓW - START\n",
      "==================================================\n",
      "\n",
      "[BACKBONE RGB]\n",
      "Warstwa 2: torch.Size([1, 96, 160, 160])\n",
      "Warstwa 4: torch.Size([1, 192, 80, 80])\n",
      "Warstwa 9: torch.Size([1, 576, 20, 20])\n",
      "\n",
      "\n",
      "[BACKBONE IR]\n",
      "Warstwa 2: torch.Size([1, 96, 160, 160])\n",
      "Warstwa 4: torch.Size([1, 192, 80, 80])\n",
      "Warstwa 9: torch.Size([1, 576, 20, 20])\n",
      "\n",
      "\n",
      "[FUZJA CECH]\n",
      "Przed fuzją - RGB[0]: torch.Size([1, 96, 160, 160]), IR[0]: torch.Size([1, 96, 160, 160])\n",
      "Po fuzji [0]: torch.Size([1, 96, 160, 160])\n",
      "\n",
      "Przed fuzją - RGB[1]: torch.Size([1, 192, 80, 80]), IR[1]: torch.Size([1, 192, 80, 80])\n",
      "Po fuzji [1]: torch.Size([1, 192, 80, 80])\n",
      "\n",
      "Przed fuzją - RGB[2]: torch.Size([1, 576, 20, 20]), IR[2]: torch.Size([1, 576, 20, 20])\n",
      "Po fuzji [2]: torch.Size([1, 576, 20, 20])\n",
      "\n",
      "\n",
      "\n",
      "[NECK]\n",
      "\n",
      "Wejście do necku: P3=torch.Size([1, 96, 160, 160]), P4=torch.Size([1, 192, 80, 80]), P5=torch.Size([1, 576, 20, 20])\n",
      "Po upsample1: torch.Size([1, 576, 40, 40])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 40 but got size 80 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     78\u001b[39m model = CustomYOLO(pretrained_model, backbone_rgb, backbone_ir)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Uruchomienie walidacji\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[43mvalidate_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mvalidate_shapes\u001b[39m\u001b[34m(model, input_size)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Etap 4: Przetwarzanie w necku\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[NECK]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m neck_outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mneck_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfused\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mKońcowe wyjścia z necku:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(neck_outputs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\multimodal-YOLO\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mCustomNeck.forward\u001b[39m\u001b[34m(self, fused_features)\u001b[39m\n\u001b[32m     19\u001b[39m x = \u001b[38;5;28mself\u001b[39m.upsample1(p5)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPo upsample1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp4\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPo concat z P4: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m x_p4 = \u001b[38;5;28mself\u001b[39m.c2f_p4(x)\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 1. Expected size 40 but got size 80 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "def validate_shapes(model, input_size=(640, 640)):\n",
    "    # Generujemy dummy data\n",
    "    x_rgb = torch.randn(1, 3, *input_size)\n",
    "    x_ir = torch.randn(1, 1, *input_size)\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"WALIDACJA KSZTAŁTÓW - START\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    # Forward pass przez backbone\n",
    "    with torch.no_grad():\n",
    "        # ----------------------------\n",
    "        # Etap 1: Backbone RGB\n",
    "        # ----------------------------\n",
    "        print(\"[BACKBONE RGB]\")\n",
    "        features_rgb = []\n",
    "        x = x_rgb.clone()\n",
    "        for idx, layer in enumerate(model.backbone_rgb.layers):\n",
    "            x = layer(x)\n",
    "            if idx in model.backbone_rgb.out_idx:\n",
    "                features_rgb.append(x)\n",
    "                print(f\"Warstwa {idx}: {x.shape}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # Etap 2: Backbone IR\n",
    "        # ----------------------------\n",
    "        print(\"[BACKBONE IR]\")\n",
    "        features_ir = []\n",
    "        x = x_ir.clone()\n",
    "        for idx, layer in enumerate(model.backbone_ir.layers):\n",
    "            x = layer(x)\n",
    "            if idx in model.backbone_ir.out_idx:\n",
    "                features_ir.append(x)\n",
    "                print(f\"Warstwa {idx}: {x.shape}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # Etap 3: Fuzja cech\n",
    "        # ----------------------------\n",
    "        print(\"[FUZJA CECH]\")\n",
    "        fused = []\n",
    "        for i, (f_rgb, f_ir) in enumerate(zip(features_rgb, features_ir)):\n",
    "            print(f\"Przed fuzją - RGB[{i}]: {f_rgb.shape}, IR[{i}]: {f_ir.shape}\")\n",
    "            fused.append(f_rgb + f_ir)\n",
    "            print(f\"Po fuzji [{i}]: {fused[-1].shape}\\n\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # Etap 4: Przetwarzanie w necku\n",
    "        # ----------------------------\n",
    "        print(\"[NECK]\")\n",
    "        neck_outputs = model.neck_head(fused)\n",
    "        print(\"\\nKońcowe wyjścia z necku:\")\n",
    "        for i, out in enumerate(neck_outputs):\n",
    "            print(f\"Output {i}: {out.shape}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # Etap 5: Warstwa Detect\n",
    "        # ----------------------------\n",
    "        print(\"[DETECT]\")\n",
    "        print(\"Wejścia do Detect:\", [o.shape for o in neck_outputs])\n",
    "        detect_output = model.detect(neck_outputs)\n",
    "        \n",
    "        print(\"\\nKońcowe wyjścia Detect:\")\n",
    "        if isinstance(detect_output, tuple):\n",
    "            for i, out in enumerate(detect_output):\n",
    "                print(f\"Output {i}: {out.shape}\")\n",
    "        else:\n",
    "            print(detect_output.shape)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"WALIDACJA ZAKOŃCZONA\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = CustomYOLO(pretrained_model, backbone_rgb, backbone_ir)\n",
    "\n",
    "# Uruchomienie walidacji\n",
    "validate_shapes(model, input_size=(640, 640))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
